## informed_adversary_mnist_reconstruction

This is a minimal implementation of a training data reconstruction attack with
an informed adversary on MNIST, as described in
[Balle et al. (2021)](https://arxiv.org/abs/2201.04845).

## Usage

Usage instructions are included in the Colabs which open and run on the
free-to-use Google Colab platform - just click the buttons below! Improved
performance and longer timeouts are available with Colab Pro.

informed_adversary_mnist_reconstruction [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepmind/informed_adversary_mnist_reconstruction/blob/master/informed_adversary_mnist_reconstruction.ipynb)

## Citing this work

If you use this code (or any derived code),
please cite the relevant accompanying [paper](https://www.computer.org/csdl/proceedings-article/sp/2022/131600b556/1CIO84VpJFm).

```
@INPROCEEDINGS {,
author = {B. Balle and G. Cherubin and J. Hayes},
booktitle = {2022 2022 IEEE Symposium on Security and Privacy (SP) (SP)},
title = {Reconstructing Training Data with Informed Adversaries},
year = {2022},
volume = {},
issn = {2375-1207},
pages = {1556-1556},
keywords = {machine-learning,-neural-networks,-reconstruction-attacks,-differential-privacy},
doi = {10.1109/SP46214.2022.00127},
url = {https://doi.ieeecomputersociety.org/10.1109/SP46214.2022.00127},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}
```

## Disclaimer

This is not an official Google product.
